{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('.nbp-app-bar').toggle()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('.nbp-app-bar').toggle()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 1,
   "metadata": {
    "collapsed": true
=======
   "execution_count": 4,
   "metadata": {
    "collapsed": false
>>>>>>> Stashed changes
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from markethistory import *"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_FEATURE = 3\n",
    "NUM_ASSET = 12\n",
    "OBS_WINDOW = 50\n",
    "\n",
    "EPISODE_WINDOW = 50\n",
    "\n",
    "TXN_FEE = 0.0025\n",
    "SAMPLING_BIAS = 1.9e-3 # This number needs to be carefully chosen."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 19,
=======
   "execution_count": 25,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX5I6YeBLUif+H9p9VrAuwto7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  2539.2155\n",
      "std:  497.30222205390356\n"
     ]
    }
   ],
   "source": [
    "# Find a good SAMPLING_BIAS\n",
    "\n",
    "def sample(start, end, bias):\n",
    "    \"\"\"\n",
    "    Geometrically sample a number in [START, END)\n",
    "    \n",
    "    Input:\n",
    "    - start: the start (inclusive)\n",
    "    - end: the end (exclusive)\n",
    "    - bias: a number between 0 to 1. The closer the bias to 1, the more\n",
    "      likely to generate a sample closer to END.\n",
    "    \"\"\"\n",
    "    offset = np.random.geometric(bias)\n",
    "    return max(end - offset, start)\n",
    "\n",
    "start, end = 50, 3060 # end is the total time length of training data\n",
    "data = [sample(start, end, 1.9e-3) for _ in range(2000)]\n",
    "plt.hist(data, 40)\n",
    "plt.axis([start, end, 0, 500])\n",
    "plt.show()\n",
    "print(\"mean: \", np.mean(data))\n",
    "print(\"std: \", np.std(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read price history from database"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
=======
   "execution_count": 5,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: missing data for following coins ['DASH', 'FCT', 'GNT', 'ZEC']\n"
     ]
    }
   ],
   "source": [
    "start = '2017/09/01'\n",
    "end = '2017/12/01'\n",
    "markethistory = MarketHistory(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add constant cash (BTC) price info"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
=======
   "execution_count": 27,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global data tensor shape: (3, 12, 4371)\n"
     ]
    }
   ],
   "source": [
    "data_global = markethistory.data\n",
    "num_feature, num_asset, T = data_global.shape\n",
    "btc_price_tensor = np.ones((num_feature, 1, T))\n",
    "data_global = np.concatenate((btc_price_tensor, data_global), axis=1)\n",
    "print(\"Global data tensor shape:\", data_global.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train, validataion, test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 22,
=======
   "execution_count": 28,
>>>>>>> Stashed changes
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6cd4dbcf1625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mT_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mT_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_global\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mT_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_global\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mT_train\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mT_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "T_test = int(0.1 * T)\n",
    "T_valid = int(0.2 * T)\n",
    "T_train = T - T_test - T_valid\n",
    "\n",
    "data_global = torch.tensor(data_global, dtype=torch.float)\n",
    "data_train = data_global[:, :, :T_train]\n",
    "data_valid = data_global[:, :, T_train:T_train+T_valid]\n",
    "data_test = data_global[:, :, T_train+T_valid:]\n",
    "print(\"Training data tensor shape:   \", data_train.shape)\n",
    "print(\"Validation data tensor shape: \", data_valid.shape)\n",
    "print(\"Testing data tensor shape:    \", data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PortfolioManager:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_policy(self,data):\n",
    "        num_feature, num_asset, T = data.shape\n",
    "        btc_price_tensor = np.ones((num_feature, 1, T))\n",
    "        data_global = np.concatenate((btc_price_tensor, data), axis=1)\n",
    "        data_tensor = torch.tensor(data_global, dtype=torch.float)\n",
    "        allocations = np.zeros((T,num_asset + 1))\n",
    "        allocations[:OBS_WINDOW,:] = np.ones(OBS_WINDOW)\n",
    "        start_w = np.zeros((1,num_asset + 1))\n",
    "        start_w[-1] = 1\n",
    "        w = torch.tensor(start_w, dtype=torch.float)\n",
    "        for t in range(OBS_WINDOW,T):\n",
    "            obs = get_observation(t,data_tensor)\n",
    "            w = model.forward(obs,w)\n",
    "            allocations[t] = w.data.numpy().squeeze()\n",
    "        self.allocations = allocations\n",
    "        return allocations   \n",
    "\n",
    "class DecisionNetwork_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    An EIIE style decision network implemented with CNN without separate\n",
    "    cash bias.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DecisionNetwork_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=NUM_FEATURE, \n",
    "                               out_channels=NUM_FEATURE, \n",
    "                               kernel_size=[1,NUM_FEATURE]) # can also use [1,2]\n",
    "        self.conv2 = nn.Conv2d(in_channels=NUM_FEATURE, \n",
    "                               out_channels=20, # can also use 10\n",
    "                               kernel_size=[1, OBS_WINDOW-2])\n",
    "        self.conv3 = nn.Conv2d(in_channels=21, \n",
    "                               out_channels=1, \n",
    "                               kernel_size=[1, 1])\n",
    "        \n",
    "    def forward(self, obs, prev_pf_w):\n",
    "        \"\"\"\n",
    "        Compute the forward pass. \n",
    "        \n",
    "        Input:\n",
    "        - obs: A fresh observation of the market environment at the current time step.\n",
    "          A tensor of shape [BATCH_SIZE, NUM_FEATURE, NUM_ASSET, OBS_WINDOW].\n",
    "        - prev_pf_w: The portfolio weight vector in the previous time step. A tensor\n",
    "          of shape [BATCH_SIZE, NUM_ASSET].\n",
    "        \n",
    "        Returns:\n",
    "        - new_pf_w: The new portfolio weight vector for the current time step. A tensor\n",
    "          of shape [BATCH_SIZE, NUM_ASSET]\n",
    "        \"\"\"\n",
    "        scores = nn.ReLU()(self.conv1(obs))\n",
    "        scores = nn.ReLU()(self.conv2(scores))\n",
    "        scores = torch.cat([scores, prev_pf_w.view(BATCH_SIZE, 1, NUM_ASSET, 1)], dim=1)\n",
    "        scores = self.conv3(scores).squeeze()\n",
    "        \n",
    "        new_pf_w = F.softmax(scores, dim=1)\n",
    "        return new_pf_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(start, end, bias):\n",
    "    \"\"\"\n",
    "    Geometrically sample a number in [START, END)\n",
    "    \n",
    "    Input:\n",
    "    - start: the start (inclusive)\n",
    "    - end: the end (exclusive)\n",
    "    - bias: a number between 0 to 1. The closer the bias to 1, the more\n",
    "      likely to generate a sample closer to END.\n",
    "    \"\"\"\n",
    "    offset = np.random.geometric(bias)\n",
    "    return max(end - offset, start)\n",
    "\n",
    "def sample_batch(batch_size, start, end, bias):\n",
    "    \"\"\"\n",
    "    Sample a batch of numbers geometrically distributed in [START, END)\n",
    "    \"\"\"\n",
    "    return torch.tensor([sample(start, end, bias) for _ in range(batch_size)])\n",
    "\n",
    "def get_observation(end_t_batch, history):\n",
    "    \"\"\"\n",
    "    Get a batch of price history of length OBS_WINDOW, ending at END_T_BATCH (inclusive).\n",
    "    \n",
    "    Input:\n",
    "    - end_t_batch: The end time indices of this observation. Shape: [BATCH_SIZE].\n",
    "    - history: The price history tensor of shape [NUM_FEATURE, NUM_ASSET, T]\n",
    "    \n",
    "    Returns:\n",
    "    - obs: A torch tensor of shape [BATCH_SIZE, NUM_FEATURE, NUM_ASSET, OBS_WINDOW]\n",
    "    \"\"\"\n",
    "    obs = []\n",
    "    for offset in range(OBS_WINDOW-1, -1, -1):\n",
    "        t_batch = end_t_batch - offset\n",
    "        observation = history[:, :, t_batch].permute(2, 0, 1)\n",
    "        obs.append(observation)\n",
    "    obs = torch.stack(obs, dim=-1)\n",
    "    \n",
    "    # normalize each asset's prices by its lastest closing prices\n",
    "    last_close_prices = obs[:, 0, :, -1]\n",
    "    tmp = obs.permute([1, 3, 0, 2]) / last_close_prices\n",
    "    obs = tmp.permute([2, 0, 3, 1])\n",
    "    \n",
    "    return obs\n",
    "\n",
    "def calculate_shrinkage(w, w_prev):\n",
    "    \"\"\"\n",
    "    Calculate the porfolio value shrinkage during a portfolio weight re-allocation due\n",
    "    to transaction fees.\n",
    "    This function calculates the shrinkage using an iterative approximation method. See\n",
    "    equation (14) of the Deep Portfolio Management paper. \n",
    "    \n",
    "    Input:\n",
    "    - w: Target portfolio weight tensor of shape [BATCH_SIZE, NUM_ASSET]\n",
    "    - w_prev: Previous portfolio weight tensor of shape [BATCH_SIZE, NUM_ASSET]\n",
    "    \n",
    "    Returns:\n",
    "    - shrinkage: Portfolio value shrinkage multipler tensor of shape [BATCH_SIZE]\n",
    "    \"\"\"\n",
    "    w0_0, w0_m = w_prev[:, 0], w_prev[:, 1:]\n",
    "    w1_0, w1_m = w[:, 0], w[:, 1:]\n",
    "    \n",
    "    const1 = 1 - TXN_FEE * w0_0\n",
    "    const2 = 2 * TXN_FEE - TXN_FEE ** 2\n",
    "    const3 = 1 - TXN_FEE * w1_0\n",
    "    \n",
    "    u = TXN_FEE * torch.sum(torch.abs(w0_m - w1_m))\n",
    "    w1_m_T = w1_m.transpose(0, 1)\n",
    "    while True:\n",
    "        u_next = (const1 - const2*torch.sum(F.relu(w0_m - (u*w1_m_T).transpose(0,1)), dim=1)) / const3\n",
    "        max_diff = torch.max(torch.abs(u - u_next))\n",
    "        if max_diff <= 1e-10:\n",
    "            return u_next\n",
    "        u = u_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: instaed of fixed window size, try randomized window size\n",
    "# TODO: modify data matrix so that it includes a row of 1 for Cash\n",
    "# TODO: think of better way to initialize the initial pf weights\n",
    "\n",
    "def train(policy, data, lr=1e-3, episodes=10000):\n",
    "    optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "    T = data.shape[-1]\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        # geometrically sample start times: [batch]\n",
    "        start_indices = sample_batch(BATCH_SIZE, OBS_WINDOW, T-EPISODE_WINDOW, SAMPLING_BIAS)\n",
    "        # initialize portfolio weights: [batch, asset]\n",
    "        pf_w = (torch.ones(NUM_ASSET) / NUM_ASSET).repeat(BATCH_SIZE, 1)\n",
    "        # initialize portfolio values: [batch]\n",
    "        pf_v = torch.ones(BATCH_SIZE)\n",
    "        \n",
    "        # simulate one episode of live trading with the policy\n",
    "        loss = 0\n",
    "        price_curr = data[0, :, start_indices].transpose(0, 1) # [batch, asset]\n",
    "        for t in range(0, EPISODE_WINDOW):\n",
    "            price_next = data[0, :, start_indices+t+1].transpose(0, 1) # [batch, asset]\n",
    "            obs = get_observation(start_indices+t, data)\n",
    "            \n",
    "            pf_w_t_start = policy.forward(obs, pf_w)\n",
    "            shrinkage = calculate_shrinkage(pf_w_t_start, pf_w)\n",
    "            pf_v_t_start = pf_v * shrinkage\n",
    "            \n",
    "            w_tmp = (price_next / price_curr) * pf_w_t_start # [batch, asset]\n",
    "            w_tmp_sum = torch.sum(w_tmp, dim=1) # [batch]\n",
    "            pf_v_t_end = w_tmp_sum * pf_v_t_start\n",
    "            pf_w_t_end = w_tmp / w_tmp_sum.view(BATCH_SIZE, 1)\n",
    "            \n",
    "            batch_reward = torch.log(pf_v_t_end / pf_v)\n",
    "            loss -= torch.sum(batch_reward) / BATCH_SIZE\n",
    "            \n",
    "            # update variables\n",
    "            pf_w = pf_w_t_end\n",
    "            pf_v = pf_v_t_end\n",
    "            price_curr = price_next\n",
    "        loss /= EPISODE_WINDOW\n",
    "        \n",
    "        #if i %  == 0:\n",
    "        print(\"episode\", i, \" loss:\", float(loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE REAL DEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "policy = DecisionNetwork_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0  loss: 0.0003386763855814934\n",
      "episode 1  loss: -0.00015338226512540132\n",
      "episode 2  loss: -0.00021559438027907163\n",
      "episode 3  loss: -0.00019199166854377836\n",
      "episode 4  loss: -0.0001881276402855292\n",
      "episode 5  loss: -0.00023184716701507568\n",
      "episode 6  loss: -0.00031151899020187557\n",
      "episode 7  loss: -0.0004567309224512428\n",
      "episode 8  loss: -0.0005689124809578061\n",
      "episode 9  loss: -0.0006198047194629908\n",
      "episode 10  loss: -0.0004756269627250731\n",
      "episode 11  loss: -0.0006415104726329446\n",
      "episode 12  loss: -0.00041835103183984756\n",
      "episode 13  loss: -0.0007897865725681186\n",
      "episode 14  loss: -0.0003440174332354218\n",
      "episode 15  loss: -0.0005216063582338393\n",
      "episode 16  loss: -0.00044860001071356237\n",
      "episode 17  loss: -0.0008784689125604928\n",
      "episode 18  loss: -0.0008838790818117559\n",
      "episode 19  loss: -0.0007863071514293551\n",
      "episode 20  loss: -0.0007667401223443449\n",
      "episode 21  loss: -0.0007864072686061263\n",
      "episode 22  loss: -0.0007116459310054779\n",
      "episode 23  loss: -0.0007850996917113662\n",
      "episode 24  loss: -0.001147543080151081\n",
      "episode 25  loss: -0.0006765787838958204\n",
      "episode 26  loss: -0.0009857689728960395\n",
      "episode 27  loss: -0.0010281011927872896\n",
      "episode 28  loss: -0.0008751875138841569\n",
      "episode 29  loss: -0.0010524835670366883\n",
      "episode 30  loss: -0.0008543561561964452\n",
      "episode 31  loss: -0.0007578778313472867\n",
      "episode 32  loss: -0.0004492505395319313\n",
      "episode 33  loss: -0.0009066715138033032\n",
      "episode 34  loss: -0.0005529783666133881\n",
      "episode 35  loss: -0.0008925077272579074\n",
      "episode 36  loss: -0.0006687076529487967\n",
      "episode 37  loss: -0.0010234426008537412\n",
      "episode 38  loss: -0.0010785282356664538\n",
      "episode 39  loss: -0.0010551082668825984\n",
      "episode 40  loss: -0.0007406387012451887\n",
      "episode 41  loss: -0.0008734205621294677\n",
      "episode 42  loss: -0.0008915255311876535\n",
      "episode 43  loss: -0.000763160060159862\n",
      "episode 44  loss: -0.00102028448600322\n",
      "episode 45  loss: -0.0009300375822931528\n",
      "episode 46  loss: -0.001343761570751667\n",
      "episode 47  loss: -0.0006737998919561505\n",
      "episode 48  loss: -0.0012553231790661812\n",
      "episode 49  loss: -0.0009249683353118598\n",
      "episode 50  loss: -0.0012720555532723665\n",
      "episode 51  loss: -0.0008785175741650164\n",
      "episode 52  loss: -0.0009649632847867906\n",
      "episode 53  loss: -0.0013435883447527885\n",
      "episode 54  loss: -0.001252010348252952\n",
      "episode 55  loss: -0.0010194005444645882\n",
      "episode 56  loss: -0.0012824025470763445\n",
      "episode 57  loss: -0.001080575049854815\n",
      "episode 58  loss: -0.001116040046326816\n",
      "episode 59  loss: -0.0009317068615928292\n",
      "episode 60  loss: -0.0008599376888014376\n",
      "episode 61  loss: -0.0011311331763863564\n",
      "episode 62  loss: -0.0010031827259808779\n",
      "episode 63  loss: -0.0011033447226509452\n",
      "episode 64  loss: -0.0012550326064229012\n",
      "episode 65  loss: -0.0009503555484116077\n",
      "episode 66  loss: -0.0013228047173470259\n",
      "episode 67  loss: -0.0010062361834570765\n",
      "episode 68  loss: -0.0014334574807435274\n",
      "episode 69  loss: -0.0009794477373361588\n",
      "episode 70  loss: -0.000699600437656045\n",
      "episode 71  loss: -0.0010188029846176505\n",
      "episode 72  loss: -0.0010032164864242077\n",
      "episode 73  loss: -0.0011615457478910685\n",
      "episode 74  loss: -0.0010187329025939107\n",
      "episode 75  loss: -0.001013037865050137\n",
      "episode 76  loss: -0.0009377647656947374\n",
      "episode 77  loss: -0.001524689607322216\n",
      "episode 78  loss: -0.001312069594860077\n",
      "episode 79  loss: -0.0010698504047468305\n",
      "episode 80  loss: -0.0015049953944981098\n",
      "episode 81  loss: -0.0010108184069395065\n",
      "episode 82  loss: -0.0012319419765844941\n",
      "episode 83  loss: -0.0009368069586344063\n",
      "episode 84  loss: -0.0010766613995656371\n",
      "episode 85  loss: -0.0012035969411954284\n",
      "episode 86  loss: -0.0009002459119074047\n",
      "episode 87  loss: -0.0010783259058371186\n",
      "episode 88  loss: -0.001164464745670557\n",
      "episode 89  loss: -0.0011671067913994193\n",
      "episode 90  loss: -0.0012577661545947194\n",
      "episode 91  loss: -0.0011681809555739164\n",
      "episode 92  loss: -0.0011383441742509604\n",
      "episode 93  loss: -0.001170489122159779\n",
      "episode 94  loss: -0.0014589071506634355\n",
      "episode 95  loss: -0.001527737476862967\n",
      "episode 96  loss: -0.0013155958149582148\n",
      "episode 97  loss: -0.0009765708819031715\n",
      "episode 98  loss: -0.0011587678454816341\n",
      "episode 99  loss: -0.001347213052213192\n",
      "episode 100  loss: -0.0011025478597730398\n",
      "episode 101  loss: -0.0008548327023163438\n",
      "episode 102  loss: -0.0013851947151124477\n",
      "episode 103  loss: -0.0009942023316398263\n",
      "episode 104  loss: -0.0012987522641196847\n",
      "episode 105  loss: -0.0013116096379235387\n",
      "episode 106  loss: -0.0011441099923104048\n",
      "episode 107  loss: -0.00122868234757334\n",
      "episode 108  loss: -0.001498099067248404\n",
      "episode 109  loss: -0.0010676399106159806\n",
      "episode 110  loss: -0.0010345539776608348\n",
      "episode 111  loss: -0.00148213398642838\n",
      "episode 112  loss: -0.001201324281282723\n",
      "episode 113  loss: -0.0014533735811710358\n",
      "episode 114  loss: -0.0012354952050372958\n",
      "episode 115  loss: -0.0016001706244423985\n",
      "episode 116  loss: -0.001215019030496478\n",
      "episode 117  loss: -0.0011256021680310369\n",
      "episode 118  loss: -0.0007757536950521171\n",
      "episode 119  loss: -0.0009135172003880143\n",
      "episode 120  loss: -0.0014446735149249434\n",
      "episode 121  loss: -0.0009758531232364476\n",
      "episode 122  loss: -0.0006903986795805395\n",
      "episode 123  loss: -0.0010015349835157394\n",
      "episode 124  loss: -0.001382491085678339\n",
      "episode 125  loss: -0.0012749605812132359\n",
      "episode 126  loss: -0.0009361671400256455\n",
      "episode 127  loss: -0.001057337038218975\n",
      "episode 128  loss: -0.0014247874496504664\n",
      "episode 129  loss: -0.0015706676058471203\n",
      "episode 130  loss: -0.0012334620114415884\n",
      "episode 131  loss: -0.0013617859221994877\n",
      "episode 132  loss: -0.0011507404269650578\n",
      "episode 133  loss: -0.0013949427520856261\n",
      "episode 134  loss: -0.00137911771889776\n",
      "episode 135  loss: -0.0009899885626509786\n",
      "episode 136  loss: -0.0011138507397845387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-47c194715838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-d65ad60b8a8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, data, lr, episodes)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPISODE_WINDOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprice_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_indices\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, asset]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_indices\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mpf_w_t_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpf_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-97e944e76463>\u001b[0m in \u001b[0;36mget_observation\u001b[0;34m(end_t_batch, history)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOBS_WINDOW\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_t_batch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(policy, data_train, lr=0.1, episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
<<<<<<< Updated upstream
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
=======
>>>>>>> Stashed changes
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< Updated upstream
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
>>>>>>> Stashed changes
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.6.3"
=======
   "version": "3.5.2"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
