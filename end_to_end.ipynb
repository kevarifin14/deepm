{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('.nbp-app-bar').toggle()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('.nbp-app-bar').toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from markethistory import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_FEATURE = 3\n",
    "NUM_ASSET = 12\n",
    "OBS_WINDOW = 50\n",
    "\n",
    "EPISODE_WINDOW = 50\n",
    "\n",
    "TXN_FEE = 0.0025\n",
    "SAMPLING_BIAS = 1.9e-3 # This number needs to be carefully chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  2531.9575\n",
      "std:  520.891038216\n"
     ]
    }
   ],
   "source": [
    "# Find a good SAMPLING_BIAS\n",
    "\n",
    "def sample(start, end, bias):\n",
    "    \"\"\"\n",
    "    Geometrically sample a number in [START, END)\n",
    "    \n",
    "    Input:\n",
    "    - start: the start (inclusive)\n",
    "    - end: the end (exclusive)\n",
    "    - bias: a number between 0 to 1. The closer the bias to 1, the more\n",
    "      likely to generate a sample closer to END.\n",
    "    \"\"\"\n",
    "    offset = np.random.geometric(bias)\n",
    "    return max(end - offset, start)\n",
    "\n",
    "start, end = 50, 3060 # end is the total time length of training data\n",
    "data = [sample(start, end, 1.9e-3) for _ in range(2000)]\n",
    "plt.hist(data, 40)\n",
    "plt.axis([start, end, 0, 500])\n",
    "plt.show()\n",
    "print(\"mean: \", np.mean(data))\n",
    "print(\"std: \", np.std(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read price history from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: missing data for following coins ['DASH', 'FCT', 'GNT', 'ZEC']\n"
     ]
    }
   ],
   "source": [
    "start = '2017/09/01'\n",
    "end = '2017/12/01'\n",
    "markethistory = MarketHistory(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add constant cash (BTC) price info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global data tensor shape: (3, 12, 4371)\n"
     ]
    }
   ],
   "source": [
    "data_global = markethistory.data\n",
    "num_feature, num_asset, T = data_global.shape\n",
    "btc_price_tensor = np.ones((num_feature, 1, T))\n",
    "data_global = np.concatenate((btc_price_tensor, data_global), axis=1)\n",
    "print(\"Global data tensor shape:\", data_global.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train, validataion, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data tensor shape:    torch.Size([3, 12, 3060])\n",
      "Validation data tensor shape:  torch.Size([3, 12, 874])\n",
      "Testing data tensor shape:     torch.Size([3, 12, 437])\n"
     ]
    }
   ],
   "source": [
    "T_test = int(0.1 * T)\n",
    "T_valid = int(0.2 * T)\n",
    "T_train = T - T_test - T_valid\n",
    "\n",
    "data_global = torch.tensor(data_global, dtype=torch.float)\n",
    "data_train = data_global[:, :, :T_train]\n",
    "data_valid = data_global[:, :, T_train:T_train+T_valid]\n",
    "data_test = data_global[:, :, T_train+T_valid:]\n",
    "print(\"Training data tensor shape:   \", data_train.shape)\n",
    "print(\"Validation data tensor shape: \", data_valid.shape)\n",
    "print(\"Testing data tensor shape:    \", data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNetwork_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    An EIIE style decision network implemented with CNN without separate\n",
    "    cash bias.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DecisionNetwork_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=NUM_FEATURE, \n",
    "                               out_channels=NUM_FEATURE, \n",
    "                               kernel_size=[1,NUM_FEATURE]) # can also use [1,2]\n",
    "        self.conv2 = nn.Conv2d(in_channels=NUM_FEATURE, \n",
    "                               out_channels=20, # can also use 10\n",
    "                               kernel_size=[1, OBS_WINDOW-2])\n",
    "        self.conv3 = nn.Conv2d(in_channels=21, \n",
    "                               out_channels=1, \n",
    "                               kernel_size=[1, 1])\n",
    "        \n",
    "    def forward(self, obs, prev_pf_w):\n",
    "        \"\"\"\n",
    "        Compute the forward pass. \n",
    "        \n",
    "        Input:\n",
    "        - obs: A fresh observation of the market environment at the current time step.\n",
    "          A tensor of shape [BATCH_SIZE, NUM_FEATURE, NUM_ASSET, OBS_WINDOW].\n",
    "        - prev_pf_w: The portfolio weight vector in the previous time step. A tensor\n",
    "          of shape [BATCH_SIZE, NUM_ASSET].\n",
    "        \n",
    "        Returns:\n",
    "        - new_pf_w: The new portfolio weight vector for the current time step. A tensor\n",
    "          of shape [BATCH_SIZE, NUM_ASSET]\n",
    "        \"\"\"\n",
    "        scores = nn.ReLU()(self.conv1(obs))\n",
    "        scores = nn.ReLU()(self.conv2(scores))\n",
    "        scores = torch.cat([scores, prev_pf_w.view(BATCH_SIZE, 1, NUM_ASSET, 1)], dim=1)\n",
    "        scores = self.conv3(scores).squeeze()\n",
    "        \n",
    "        new_pf_w = F.softmax(scores, dim=1)\n",
    "        return new_pf_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(start, end, bias):\n",
    "    \"\"\"\n",
    "    Geometrically sample a number in [START, END)\n",
    "    \n",
    "    Input:\n",
    "    - start: the start (inclusive)\n",
    "    - end: the end (exclusive)\n",
    "    - bias: a number between 0 to 1. The closer the bias to 1, the more\n",
    "      likely to generate a sample closer to END.\n",
    "    \"\"\"\n",
    "    offset = np.random.geometric(bias)\n",
    "    return max(end - offset, start)\n",
    "\n",
    "def sample_batch(batch_size, start, end, bias):\n",
    "    \"\"\"\n",
    "    Sample a batch of numbers geometrically distributed in [START, END)\n",
    "    \"\"\"\n",
    "    return torch.tensor([sample(start, end, bias) for _ in range(batch_size)])\n",
    "\n",
    "def get_observation(end_t_batch, history):\n",
    "    \"\"\"\n",
    "    Get a batch of price history of length OBS_WINDOW, ending at END_T_BATCH (inclusive).\n",
    "    \n",
    "    Input:\n",
    "    - end_t_batch: The end time indices of this observation. Shape: [BATCH_SIZE].\n",
    "    - history: The price history tensor of shape [NUM_FEATURE, NUM_ASSET, T]\n",
    "    \n",
    "    Returns:\n",
    "    - obs: A torch tensor of shape [BATCH_SIZE, NUM_FEATURE, NUM_ASSET, OBS_WINDOW]\n",
    "    \"\"\"\n",
    "    obs = []\n",
    "    for offset in range(OBS_WINDOW-1, -1, -1):\n",
    "        t_batch = end_t_batch - offset\n",
    "        observation = history[:, :, t_batch].permute(2, 0, 1)\n",
    "        obs.append(observation)\n",
    "    obs = torch.stack(obs, dim=-1)\n",
    "    \n",
    "    # normalize each asset's prices by its lastest closing prices\n",
    "    last_close_prices = obs[:, 0, :, -1]\n",
    "    tmp = obs.permute([1, 3, 0, 2]) / last_close_prices\n",
    "    obs = tmp.permute([2, 0, 3, 1])\n",
    "    \n",
    "    return obs\n",
    "\n",
    "def calculate_shrinkage(w, w_prev):\n",
    "    \"\"\"\n",
    "    Calculate the porfolio value shrinkage during a portfolio weight re-allocation due\n",
    "    to transaction fees.\n",
    "    This function calculates the shrinkage using an iterative approximation method. See\n",
    "    equation (14) of the Deep Portfolio Management paper. \n",
    "    \n",
    "    Input:\n",
    "    - w: Target portfolio weight tensor of shape [BATCH_SIZE, NUM_ASSET]\n",
    "    - w_prev: Previous portfolio weight tensor of shape [BATCH_SIZE, NUM_ASSET]\n",
    "    \n",
    "    Returns:\n",
    "    - shrinkage: Portfolio value shrinkage multipler tensor of shape [BATCH_SIZE]\n",
    "    \"\"\"\n",
    "    w0_0, w0_m = w_prev[:, 0], w_prev[:, 1:]\n",
    "    w1_0, w1_m = w[:, 0], w[:, 1:]\n",
    "    \n",
    "    const1 = 1 - TXN_FEE * w0_0\n",
    "    const2 = 2 * TXN_FEE - TXN_FEE ** 2\n",
    "    const3 = 1 - TXN_FEE * w1_0\n",
    "    \n",
    "    u = TXN_FEE * torch.sum(torch.abs(w0_m - w1_m))\n",
    "    w1_m_T = w1_m.transpose(0, 1)\n",
    "    while True:\n",
    "        u_next = (const1 - const2*torch.sum(F.relu(w0_m - (u*w1_m_T).transpose(0,1)), dim=1)) / const3\n",
    "        max_diff = torch.max(torch.abs(u - u_next))\n",
    "        if max_diff <= 1e-10:\n",
    "            return u_next\n",
    "        u = u_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: instaed of fixed window size, try randomized window size\n",
    "# TODO: modify data matrix so that it includes a row of 1 for Cash\n",
    "# TODO: think of better way to initialize the initial pf weights\n",
    "\n",
    "def train(policy, data, lr=1e-3, episodes=10000):\n",
    "    optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "    T = data.shape[-1]\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        # geometrically sample start times: [batch]\n",
    "        start_indices = sample_batch(BATCH_SIZE, OBS_WINDOW, T-EPISODE_WINDOW, SAMPLING_BIAS)\n",
    "        # initialize portfolio weights: [batch, asset]\n",
    "        pf_w = (torch.ones(NUM_ASSET) / NUM_ASSET).repeat(BATCH_SIZE, 1)\n",
    "        # initialize portfolio values: [batch]\n",
    "        pf_v = torch.ones(BATCH_SIZE)\n",
    "        \n",
    "        # simulate one episode of live trading with the policy\n",
    "        loss = 0\n",
    "        price_curr = data[0, :, start_indices].transpose(0, 1) # [batch, asset]\n",
    "        for t in range(0, EPISODE_WINDOW):\n",
    "            price_next = data[0, :, start_indices+t+1].transpose(0, 1) # [batch, asset]\n",
    "            obs = get_observation(start_indices+t, data)\n",
    "            \n",
    "            pf_w_t_start = policy.forward(obs, pf_w)\n",
    "            shrinkage = calculate_shrinkage(pf_w_t_start, pf_w)\n",
    "            pf_v_t_start = pf_v * shrinkage\n",
    "            \n",
    "            w_tmp = (price_next / price_curr) * pf_w_t_start # [batch, asset]\n",
    "            w_tmp_sum = torch.sum(w_tmp, dim=1) # [batch]\n",
    "            pf_v_t_end = w_tmp_sum * pf_v_t_start\n",
    "            pf_w_t_end = w_tmp / w_tmp_sum.view(BATCH_SIZE, 1)\n",
    "            \n",
    "            batch_reward = torch.log(pf_v_t_end / pf_v)\n",
    "            loss -= torch.sum(batch_reward) / BATCH_SIZE\n",
    "            \n",
    "            # update variables\n",
    "            pf_w = pf_w_t_end\n",
    "            pf_v = pf_v_t_end\n",
    "            price_curr = price_next\n",
    "        loss /= EPISODE_WINDOW\n",
    "        \n",
    "        #if i %  == 0:\n",
    "        print(\"episode\", i, \" loss:\", float(loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE REAL DEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = DecisionNetwork_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0  loss: 0.0003386763855814934\n",
      "episode 1  loss: -0.00015338226512540132\n",
      "episode 2  loss: -0.00021559438027907163\n",
      "episode 3  loss: -0.00019199166854377836\n",
      "episode 4  loss: -0.0001881276402855292\n",
      "episode 5  loss: -0.00023184716701507568\n",
      "episode 6  loss: -0.00031151899020187557\n",
      "episode 7  loss: -0.0004567309224512428\n",
      "episode 8  loss: -0.0005689124809578061\n",
      "episode 9  loss: -0.0006198047194629908\n",
      "episode 10  loss: -0.0004756269627250731\n",
      "episode 11  loss: -0.0006415104726329446\n",
      "episode 12  loss: -0.00041835103183984756\n",
      "episode 13  loss: -0.0007897865725681186\n",
      "episode 14  loss: -0.0003440174332354218\n",
      "episode 15  loss: -0.0005216063582338393\n",
      "episode 16  loss: -0.00044860001071356237\n",
      "episode 17  loss: -0.0008784689125604928\n",
      "episode 18  loss: -0.0008838790818117559\n",
      "episode 19  loss: -0.0007863071514293551\n",
      "episode 20  loss: -0.0007667401223443449\n",
      "episode 21  loss: -0.0007864072686061263\n",
      "episode 22  loss: -0.0007116459310054779\n",
      "episode 23  loss: -0.0007850996917113662\n",
      "episode 24  loss: -0.001147543080151081\n",
      "episode 25  loss: -0.0006765787838958204\n",
      "episode 26  loss: -0.0009857689728960395\n",
      "episode 27  loss: -0.0010281011927872896\n",
      "episode 28  loss: -0.0008751875138841569\n",
      "episode 29  loss: -0.0010524835670366883\n",
      "episode 30  loss: -0.0008543561561964452\n",
      "episode 31  loss: -0.0007578778313472867\n",
      "episode 32  loss: -0.0004492505395319313\n",
      "episode 33  loss: -0.0009066715138033032\n",
      "episode 34  loss: -0.0005529783666133881\n",
      "episode 35  loss: -0.0008925077272579074\n",
      "episode 36  loss: -0.0006687076529487967\n",
      "episode 37  loss: -0.0010234426008537412\n",
      "episode 38  loss: -0.0010785282356664538\n",
      "episode 39  loss: -0.0010551082668825984\n",
      "episode 40  loss: -0.0007406387012451887\n",
      "episode 41  loss: -0.0008734205621294677\n",
      "episode 42  loss: -0.0008915255311876535\n",
      "episode 43  loss: -0.000763160060159862\n",
      "episode 44  loss: -0.00102028448600322\n",
      "episode 45  loss: -0.0009300375822931528\n",
      "episode 46  loss: -0.001343761570751667\n",
      "episode 47  loss: -0.0006737998919561505\n",
      "episode 48  loss: -0.0012553231790661812\n",
      "episode 49  loss: -0.0009249683353118598\n",
      "episode 50  loss: -0.0012720555532723665\n",
      "episode 51  loss: -0.0008785175741650164\n",
      "episode 52  loss: -0.0009649632847867906\n",
      "episode 53  loss: -0.0013435883447527885\n",
      "episode 54  loss: -0.001252010348252952\n",
      "episode 55  loss: -0.0010194005444645882\n",
      "episode 56  loss: -0.0012824025470763445\n",
      "episode 57  loss: -0.001080575049854815\n",
      "episode 58  loss: -0.001116040046326816\n",
      "episode 59  loss: -0.0009317068615928292\n",
      "episode 60  loss: -0.0008599376888014376\n",
      "episode 61  loss: -0.0011311331763863564\n",
      "episode 62  loss: -0.0010031827259808779\n",
      "episode 63  loss: -0.0011033447226509452\n",
      "episode 64  loss: -0.0012550326064229012\n",
      "episode 65  loss: -0.0009503555484116077\n",
      "episode 66  loss: -0.0013228047173470259\n",
      "episode 67  loss: -0.0010062361834570765\n",
      "episode 68  loss: -0.0014334574807435274\n",
      "episode 69  loss: -0.0009794477373361588\n",
      "episode 70  loss: -0.000699600437656045\n",
      "episode 71  loss: -0.0010188029846176505\n",
      "episode 72  loss: -0.0010032164864242077\n",
      "episode 73  loss: -0.0011615457478910685\n",
      "episode 74  loss: -0.0010187329025939107\n",
      "episode 75  loss: -0.001013037865050137\n",
      "episode 76  loss: -0.0009377647656947374\n",
      "episode 77  loss: -0.001524689607322216\n",
      "episode 78  loss: -0.001312069594860077\n",
      "episode 79  loss: -0.0010698504047468305\n",
      "episode 80  loss: -0.0015049953944981098\n",
      "episode 81  loss: -0.0010108184069395065\n",
      "episode 82  loss: -0.0012319419765844941\n",
      "episode 83  loss: -0.0009368069586344063\n",
      "episode 84  loss: -0.0010766613995656371\n",
      "episode 85  loss: -0.0012035969411954284\n",
      "episode 86  loss: -0.0009002459119074047\n",
      "episode 87  loss: -0.0010783259058371186\n",
      "episode 88  loss: -0.001164464745670557\n",
      "episode 89  loss: -0.0011671067913994193\n",
      "episode 90  loss: -0.0012577661545947194\n",
      "episode 91  loss: -0.0011681809555739164\n",
      "episode 92  loss: -0.0011383441742509604\n",
      "episode 93  loss: -0.001170489122159779\n",
      "episode 94  loss: -0.0014589071506634355\n",
      "episode 95  loss: -0.001527737476862967\n",
      "episode 96  loss: -0.0013155958149582148\n",
      "episode 97  loss: -0.0009765708819031715\n",
      "episode 98  loss: -0.0011587678454816341\n",
      "episode 99  loss: -0.001347213052213192\n",
      "episode 100  loss: -0.0011025478597730398\n",
      "episode 101  loss: -0.0008548327023163438\n",
      "episode 102  loss: -0.0013851947151124477\n",
      "episode 103  loss: -0.0009942023316398263\n",
      "episode 104  loss: -0.0012987522641196847\n",
      "episode 105  loss: -0.0013116096379235387\n",
      "episode 106  loss: -0.0011441099923104048\n",
      "episode 107  loss: -0.00122868234757334\n",
      "episode 108  loss: -0.001498099067248404\n",
      "episode 109  loss: -0.0010676399106159806\n",
      "episode 110  loss: -0.0010345539776608348\n",
      "episode 111  loss: -0.00148213398642838\n",
      "episode 112  loss: -0.001201324281282723\n",
      "episode 113  loss: -0.0014533735811710358\n",
      "episode 114  loss: -0.0012354952050372958\n",
      "episode 115  loss: -0.0016001706244423985\n",
      "episode 116  loss: -0.001215019030496478\n",
      "episode 117  loss: -0.0011256021680310369\n",
      "episode 118  loss: -0.0007757536950521171\n",
      "episode 119  loss: -0.0009135172003880143\n",
      "episode 120  loss: -0.0014446735149249434\n",
      "episode 121  loss: -0.0009758531232364476\n",
      "episode 122  loss: -0.0006903986795805395\n",
      "episode 123  loss: -0.0010015349835157394\n",
      "episode 124  loss: -0.001382491085678339\n",
      "episode 125  loss: -0.0012749605812132359\n",
      "episode 126  loss: -0.0009361671400256455\n",
      "episode 127  loss: -0.001057337038218975\n",
      "episode 128  loss: -0.0014247874496504664\n",
      "episode 129  loss: -0.0015706676058471203\n",
      "episode 130  loss: -0.0012334620114415884\n",
      "episode 131  loss: -0.0013617859221994877\n",
      "episode 132  loss: -0.0011507404269650578\n",
      "episode 133  loss: -0.0013949427520856261\n",
      "episode 134  loss: -0.00137911771889776\n",
      "episode 135  loss: -0.0009899885626509786\n",
      "episode 136  loss: -0.0011138507397845387\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-47c194715838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-d65ad60b8a8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, data, lr, episodes)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPISODE_WINDOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprice_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_indices\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, asset]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_indices\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mpf_w_t_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpf_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-97e944e76463>\u001b[0m in \u001b[0;36mget_observation\u001b[0;34m(end_t_batch, history)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOBS_WINDOW\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mt_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_t_batch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(policy, data_train, lr=0.1, episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeprlbootcamp]",
   "language": "python",
   "name": "conda-env-deeprlbootcamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
