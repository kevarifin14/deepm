{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "$('.nbp-app-bar').toggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from backtest import *\n",
    "from markethistory import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_FEATURE = 6\n",
    "NUM_ASSET = 12\n",
    "OBS_WINDOW = 50\n",
    "\n",
    "EPISODE_WINDOW = 50\n",
    "\n",
    "TXN_FEE = 0.0025\n",
    "SAMPLING_BIAS = 1.9e-3 # This number needs to be carefully chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1158994e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  2522.4385\n",
      "std:  530.970655703\n"
     ]
    }
   ],
   "source": [
    "# Find a good SAMPLING_BIAS\n",
    "\n",
    "def sample(start, end, bias):\n",
    "    \"\"\"\n",
    "    Geometrically sample a number in [START, END)\n",
    "    \n",
    "    Input:\n",
    "    - start: the start (inclusive)\n",
    "    - end: the end (exclusive)\n",
    "    - bias: a number between 0 to 1. The closer the bias to 1, the more\n",
    "      likely to generate a sample closer to END.\n",
    "    \"\"\"\n",
    "    offset = np.random.geometric(bias)\n",
    "    return max(end - offset, start)\n",
    "\n",
    "start, end = 50, 3060 # end is the total time length of training data\n",
    "data = [sample(start, end, 1.9e-3) for _ in range(2000)]\n",
    "plt.hist(data, 40)\n",
    "plt.axis([start, end, 0, 500])\n",
    "plt.show()\n",
    "print(\"mean: \", np.mean(data))\n",
    "print(\"std: \", np.std(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('config.json') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read price history from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: missing data for following coins ['DASH', 'FCT', 'GNT', 'ZEC']\n"
     ]
    }
   ],
   "source": [
    "markethistory = MarketHistory(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add constant cash (BTC) price info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global data tensor shape: (6, 12, 11089)\n"
     ]
    }
   ],
   "source": [
    "data_global = markethistory.data\n",
    "num_feature, num_asset, T = data_global.shape\n",
    "btc_price_tensor = np.ones((num_feature, 1, T))\n",
    "data_global = np.concatenate((btc_price_tensor, data_global), axis=1)\n",
    "print(\"Global data tensor shape:\", data_global.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train, validataion, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data tensor shape:    torch.Size([6, 12, 7764])\n",
      "Validation data tensor shape:  torch.Size([6, 12, 2217])\n",
      "Testing data tensor shape:     torch.Size([6, 12, 1108])\n"
     ]
    }
   ],
   "source": [
    "T = data_global.shape[-1]\n",
    "T_test = int(0.1 * T)\n",
    "T_valid = int(0.2 * T)\n",
    "T_train = T - T_test - T_valid\n",
    "\n",
    "data_global = torch.from_numpy(data_global)\n",
    "data_train = data_global[:, :, :T_train]\n",
    "data_valid = data_global[:, :, T_train:T_train+T_valid]\n",
    "data_test = data_global[:, :, T_train+T_valid:]\n",
    "print(\"Training data tensor shape:   \", data_train.shape)\n",
    "print(\"Validation data tensor shape: \", data_valid.shape)\n",
    "print(\"Testing data tensor shape:    \", data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy = DecisionNetwork_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pm = PortfolioManager(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a9464023c10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2018/1/15\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2018/2/1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBacktest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_testing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kevin/Google Drive/Berkeley/classes/cs194-129/project/deepm/backtest.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, agent, start_training, end_training, start_testing, end_testing, period, include_fees)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_testing_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_testing_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmh_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMarketHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmh_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraded_coins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmh_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "agent = pm\n",
    "start_training = \"2017/12/15\"\n",
    "end_training = \"2018/1/1\"\n",
    "start_testing = \"2018/1/15\"\n",
    "end_testing = \"2018/2/1\"\n",
    "bt = Backtest(pm,start_training,end_training,start_testing,end_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bt.plot_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PortfolioManager:\n",
    "    \"\"\"\n",
    "    Capsule taking in a trained model to be called by backtest.py.\n",
    "    get_policy(data) returns a numpy array of shape [T, NUM_ASSET].\n",
    "    For the first \"OBS_WINDOW\" observations, allocation is considered to be entirely cash.\n",
    "    Portfolio manager doesn't trade if recommended allocation for a particular asset is less than a threshold CUTOFF_TRADE.\n",
    "    \"\"\"\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_policy(self,data):\n",
    "        num_feature, num_asset, T = data.shape\n",
    "        btc_price_tensor = np.ones((num_feature, 1, T))\n",
    "        data_global = np.concatenate((btc_price_tensor, data), axis=1)\n",
    "        data_tensor = torch.from_numpy(data_global)\n",
    "        allocations = np.zeros((T,num_asset + 1))\n",
    "        allocations[:OBS_WINDOW,-1] = np.ones(OBS_WINDOW)\n",
    "        start_w = np.zeros((1,num_asset + 1))\n",
    "        start_w[:,-1] = 1\n",
    "        w = torch.from_numpy(start_w)\n",
    "        for t in range(OBS_WINDOW,T):\n",
    "            obs = get_observation(np.array([t]),data_tensor)\n",
    "            obs = obs.type(torch.float32)\n",
    "            w = self.model.forward(obs,w)\n",
    "            allocations[t] = w.data.numpy().squeeze()\n",
    "        self.allocations = allocations\n",
    "        alloc_without_cash = allocations[:,:-1]\n",
    "        alloc_without_cash[np.abs(alloc_without_cash) < CUTOFF_TRADE] = 0\n",
    "        return alloc_without_cash\n",
    "\n",
    "class DecisionNetwork_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    An EIIE style decision network implemented with CNN without separate\n",
    "    cash bias.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(DecisionNetwork_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=NUM_FEATURE, \n",
    "                               out_channels=NUM_FEATURE, \n",
    "                               kernel_size=[1,NUM_FEATURE]) # can also use [1,2]\n",
    "        self.conv2 = nn.Conv2d(in_channels=NUM_FEATURE, \n",
    "                               out_channels=20, # can also use 10\n",
    "                               kernel_size=[1, OBS_WINDOW-2])\n",
    "        self.conv3 = nn.Conv2d(in_channels=21, \n",
    "                               out_channels=1, \n",
    "                               kernel_size=[1, 1])\n",
    "        \n",
    "    def forward(self, obs, prev_pf_w):\n",
    "        \"\"\"\n",
    "        Compute the forward pass. \n",
    "        \n",
    "        Input:\n",
    "        - obs: A fresh observation of the market environment at the current time step.\n",
    "          A tensor of shape [BATCH_SIZE, NUM_FEATURE, NUM_ASSET, OBS_WINDOW].\n",
    "        - prev_pf_w: The portfolio weight vector in the previous time step. A tensor\n",
    "          of shape [BATCH_SIZE, NUM_ASSET].\n",
    "        \n",
    "        Returns:\n",
    "        - new_pf_w: The new portfolio weight vector for the current time step. A tensor\n",
    "          of shape [BATCH_SIZE, NUM_ASSET]\n",
    "        \"\"\"\n",
    "        batch_size, num_features,num_asset,window_length = obs.size()\n",
    "        scores = nn.ReLU()(self.conv1(obs))\n",
    "        scores = nn.ReLU()(self.conv2(scores))\n",
    "        scores = torch.cat([scores, prev_pf_w.view(batch_size, 1, num_asset, 1).float()], dim=1)\n",
    "        scores = self.conv3(scores).squeeze()\n",
    "        if batch_size == 1:\n",
    "            dim = 0\n",
    "        else:\n",
    "            dim = 1\n",
    "        new_pf_w = F.softmax(scores, dim=dim)\n",
    "        return new_pf_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define helper functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(start, end, bias):\n",
    "    \"\"\"\n",
    "    Geometrically sample a number in [START, END)\n",
    "    \n",
    "    Input:\n",
    "    - start: the start (inclusive)\n",
    "    - end: the end (exclusive)\n",
    "    - bias: a number between 0 to 1. The closer the bias to 1, the more\n",
    "      likely to generate a sample closer to END.\n",
    "    \"\"\"\n",
    "    offset = np.random.geometric(bias)\n",
    "    return max(end - offset, start)\n",
    "\n",
    "def sample_batch(batch_size, start, end, bias):\n",
    "    \"\"\"\n",
    "    Sample a batch of numbers geometrically distributed in [START, END)\n",
    "    \"\"\"\n",
    "    return torch.tensor([sample(start, end, bias) for _ in range(batch_size)])\n",
    "\n",
    "def get_observation(end_t_batch, history):\n",
    "    \"\"\"\n",
    "    Get a batch of price history of length OBS_WINDOW, ending at END_T_BATCH (inclusive).\n",
    "    \n",
    "    Input:\n",
    "    - end_t_batch: The end time indices of this observation. Shape: [BATCH_SIZE].\n",
    "    - history: The price history tensor of shape [NUM_FEATURE, NUM_ASSET, T]\n",
    "    \n",
    "    Returns:\n",
    "    - obs: A torch tensor of shape [BATCH_SIZE, NUM_FEATURE, NUM_ASSET, OBS_WINDOW]\n",
    "    \"\"\"\n",
    "    obs = []\n",
    "    for offset in range(OBS_WINDOW-1, -1, -1):\n",
    "        t_batch = end_t_batch - offset\n",
    "        observation = history[:, :, t_batch].permute(2, 0, 1)\n",
    "        obs.append(observation)\n",
    "    obs = torch.stack(obs, dim=-1)\n",
    "    \n",
    "    # normalize each asset's prices by its lastest closing prices\n",
    "    last_close_prices = obs[:, 0, :, -1]\n",
    "    tmp = obs.permute(1, 3, 0, 2) / last_close_prices\n",
    "    obs = tmp.permute(2, 0, 3, 1)\n",
    "    \n",
    "    return obs\n",
    "\n",
    "def calculate_shrinkage(w, w_prev):\n",
    "    \"\"\"\n",
    "    Calculate the porfolio value shrinkage during a portfolio weight re-allocation due\n",
    "    to transaction fees.\n",
    "    This function calculates the shrinkage using an iterative approximation method. See\n",
    "    equation (14) of the Deep Portfolio Management paper. \n",
    "    \n",
    "    Input:\n",
    "    - w: Target portfolio weight tensor of shape [BATCH_SIZE, NUM_ASSET]\n",
    "    - w_prev: Previous portfolio weight tensor of shape [BATCH_SIZE, NUM_ASSET]\n",
    "    \n",
    "    Returns:\n",
    "    - shrinkage: Portfolio value shrinkage multipler tensor of shape [BATCH_SIZE]\n",
    "    \"\"\"\n",
    "    w0_0, w0_m = w_prev[:, 0], w_prev[:, 1:]\n",
    "    w1_0, w1_m = w[:, 0], w[:, 1:]\n",
    "    \n",
    "    const1 = 1 - TXN_FEE * w0_0\n",
    "    const2 = 2 * TXN_FEE - TXN_FEE ** 2\n",
    "    const3 = 1 - TXN_FEE * w1_0\n",
    "    \n",
    "    u = TXN_FEE * torch.sum(torch.abs(w0_m - w1_m))\n",
    "    w1_m_T = w1_m.transpose(0, 1)\n",
    "    while True:\n",
    "        u_next = (const1 - const2*torch.sum(F.relu(w0_m - (u*w1_m_T).transpose(0,1)), dim=1)) / const3\n",
    "        max_diff = torch.max(torch.abs(u - u_next))\n",
    "        if max_diff <= 1e-10:\n",
    "            return u_next\n",
    "        u = u_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: instaed of fixed window size, try randomized window size\n",
    "# TODO: modify data matrix so that it includes a row of 1 for Cash\n",
    "# TODO: think of better way to initialize the initial pf weights\n",
    "\n",
    "def train(policy, data, lr=1e-3, episodes=10000):\n",
    "    optimizer = torch.optim.Adam(policy.parameters(), lr=lr)\n",
    "    T = data.shape[-1]\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        # geometrically sample start times: [batch]\n",
    "        start_indices = sample_batch(BATCH_SIZE, OBS_WINDOW, T-EPISODE_WINDOW, SAMPLING_BIAS)\n",
    "        # initialize portfolio weights: [batch, asset]\n",
    "        pf_w = (torch.ones(NUM_ASSET) / NUM_ASSET).repeat(BATCH_SIZE, 1)\n",
    "        # initialize portfolio values: [batch]\n",
    "        pf_v = torch.ones(BATCH_SIZE)\n",
    "        \n",
    "        # simulate one episode of live trading with the policy\n",
    "        loss = 0\n",
    "        price_curr = data[0, :, start_indices].transpose(0, 1) # [batch, asset]\n",
    "        for t in range(0, EPISODE_WINDOW):\n",
    "            price_next = data[0, :, start_indices+t+1].transpose(0, 1) # [batch, asset]\n",
    "            obs = get_observation(start_indices+t, data)\n",
    "            \n",
    "            pf_w_t_start = policy.forward(obs, pf_w)\n",
    "            shrinkage = calculate_shrinkage(pf_w_t_start, pf_w)\n",
    "            pf_v_t_start = pf_v * shrinkage\n",
    "            \n",
    "            w_tmp = (price_next / price_curr) * pf_w_t_start # [batch, asset]\n",
    "            w_tmp_sum = torch.sum(w_tmp, dim=1) # [batch]\n",
    "            pf_v_t_end = w_tmp_sum * pf_v_t_start\n",
    "            pf_w_t_end = w_tmp / w_tmp_sum.view(BATCH_SIZE, 1)\n",
    "            \n",
    "            batch_reward = torch.log(pf_v_t_end / pf_v)\n",
    "            loss -= torch.sum(batch_reward) / BATCH_SIZE\n",
    "            \n",
    "            # update variables\n",
    "            pf_w = pf_w_t_end\n",
    "            pf_v = pf_v_t_end\n",
    "            price_curr = price_next\n",
    "        loss /= EPISODE_WINDOW\n",
    "        \n",
    "        #if i %  == 0:\n",
    "        print(\"episode\", i, \" loss:\", float(loss))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE REAL DEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy = DecisionNetwork_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.DoubleTensor but found type torch.FloatTensor for argument #2 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d351f7f21273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-0b1ab6009cf3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(policy, data, lr, episodes)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_indices\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mpf_w_t_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpf_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mshrinkage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_shrinkage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpf_w_t_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpf_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mpf_v_t_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpf_v\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshrinkage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-ca97e7708b71>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs, prev_pf_w)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \"\"\"\n\u001b[1;32m     63\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_asset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_pf_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_asset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kevin/anaconda3/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.DoubleTensor but found type torch.FloatTensor for argument #2 'weight'"
     ]
    }
   ],
   "source": [
    "train(policy, data_train, lr=0.1, episodes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
